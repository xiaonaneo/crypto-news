#!/usr/bin/env python3
"""
åŠ å¯†è´§å¸æ–°é—»ç®€æŠ¥ - GitHub Actions ç‰ˆæœ¬
å®Œå…¨å¤åˆ»æœ¬åœ°è¿è¡Œæµç¨‹ï¼š
- RSS æŠ“å– â†’ å¤„ç† â†’ AIæ‘˜è¦(ç¿»è¯‘+æ‘˜è¦) â†’ ç²¾ç¾æ ¼å¼å‘é€
"""

import os, yaml, logging, ssl, urllib.request, feedparser, requests
from datetime import datetime, timedelta
from typing import List, Dict

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)

# SSL fix
ctx = ssl.create_default_context()
ctx.check_hostname = False
ctx.verify_mode = ssl.CERT_NONE
_orig = urllib.request.urlopen

def _patch(url, *a, **k):
    try: return _orig(url, *a, **k, context=ctx)
    except:
        req = urllib.request.Request(url)
        return urllib.request.urlopen(req, timeout=30)

urllib.request.urlopen = _patch


def clean_html(text):
    if not text:
        return ""
    import re
    text = re.sub(r'<[^>]+>', '', text)
    text = re.sub(r'\s+', ' ', text)
    return text.strip()


def fetch_article_content(url: str) -> str:
    """Fetch article content from URL"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()

        from bs4 import BeautifulSoup
        soup = BeautifulSoup(response.content, 'html.parser')

        for script in soup(['script', 'style', 'nav', 'footer', 'header']):
            script.decompose()

        content = None
        selectors = ['article', '[role="main"]', '.article-content', '.post-content',
                     '.entry-content', '.content-body', '.story-body', 'main']

        for selector in selectors:
            content = soup.select_one(selector)
            if content and len(content.get_text(strip=True)) > 200:
                break

        if not content:
            content = soup.find('body')

        if content:
            text = content.get_text(separator=' ', strip=True)
            text = re.sub(r'\s+', ' ', text).strip()
            return text[:3000]

        return ""
    except Exception as e:
        logger.debug(f"Failed to fetch {url}: {e}")
        return ""


def summarize_with_deepseek(title: str, summary: str, url: str = "") -> Dict[str, str]:
    """ä½¿ç”¨ DeepSeek AI ç¿»è¯‘æ ‡é¢˜å¹¶ç”Ÿæˆæ‘˜è¦ï¼ˆå¤åˆ»æœ¬åœ°é€»è¾‘ï¼‰"""
    api_key = os.environ.get("DEEPSEEK_API_KEY")

    if not api_key:
        logger.warning("DEEPSEEK_API_KEY not set, using original title")
        return {"title_cn": clean_html(title), "summary": clean_html(summary)[:200]}

    try:
        # è·å–æ–‡ç« å†…å®¹
        content = fetch_article_content(url) if url else ""

        if content:
            prompt = f"""
è¯·ç”¨ä¸­æ–‡å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

1. å°†æ ‡é¢˜ç¿»è¯‘æˆç®€æ´çš„ä¸­æ–‡ï¼ˆä¸è¶…è¿‡25å­—ï¼‰
2. é˜…è¯»æ–‡ç« å†…å®¹ï¼Œç”¨ä¸è¶…è¿‡100ä¸ªæ±‰å­—æ€»ç»“æ–‡ç« è¦ç‚¹ï¼ˆåªä¿ç•™ä¸åŠ å¯†è´§å¸ç›´æ¥ç›¸å…³çš„å†…å®¹ï¼‰

æ ‡é¢˜ï¼š{title}
æ¥æºï¼š{summary[:500]}

æ–‡ç« å†…å®¹ï¼š
{content[:2000]}

è¯·ç”¨ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
æ ‡é¢˜ç¿»è¯‘ï¼š[ä¸­æ–‡æ ‡é¢˜]
æ‘˜è¦ï¼š[ä¸è¶…è¿‡100å­—çš„æ‘˜è¦]
"""
        else:
            prompt = f"""
è¯·ç”¨ä¸­æ–‡å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

1. å°†æ ‡é¢˜ç¿»è¯‘æˆç®€æ´çš„ä¸­æ–‡ï¼ˆä¸è¶…è¿‡25å­—ï¼‰
2. æ ¹æ®æ ‡é¢˜å’Œæ‘˜è¦ç”Ÿæˆä¸€ä¸ªä¸è¶…è¿‡100å­—çš„æ‘˜è¦

æ ‡é¢˜ï¼š{title}
æ‘˜è¦ï¼š{summary[:500]}

è¯·ç”¨ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
æ ‡é¢˜ç¿»è¯‘ï¼š[ä¸­æ–‡æ ‡é¢˜]
æ‘˜è¦ï¼š[ä¸è¶…è¿‡100å­—çš„æ‘˜è¦]
"""

        response = requests.post(
            "https://api.deepseek.com/chat/completions",
            headers={
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            },
            json={
                "model": "deepseek-chat",
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 300
            },
            timeout=30
        )

        if response.status_code == 200:
            data = response.json()
            if data.get("choices") and len(data["choices"]) > 0:
                result = data["choices"][0]["message"]["content"].strip()

                title_cn = clean_html(title)
                summary_cn = clean_html(summary)[:200]

                for line in result.split('\n'):
                    if line.startswith('æ ‡é¢˜ç¿»è¯‘ï¼š'):
                        title_cn = line.replace('æ ‡é¢˜ç¿»è¯‘ï¼š', '').strip()
                    elif line.startswith('æ‘˜è¦ï¼š'):
                        summary_cn = line.replace('æ‘˜è¦ï¼š', '').strip()

                return {"title_cn": title_cn, "summary": summary_cn}

    except Exception as e:
        logger.debug(f"DeepSeek API error: {e}")

    return {"title_cn": clean_html(title), "summary": clean_html(summary)[:200]}


class RSSFetcher:
    """RSS Feed Fetcher"""
    def __init__(self, config: dict):
        self.config = config
        self.feeds = config.get("rss_sources", [])
        self.lookback_hours = config.get("processing", {}).get("hours_lookback", 12)

    def fetch_all(self) -> List[Dict]:
        articles = []
        cutoff_time = datetime.now() - timedelta(hours=self.lookback_hours)

        for feed in self.feeds:
            if not feed.get("enabled", True):
                continue

            try:
                logger.info(f"ğŸ“¡ Fetching: {feed.get('zh_name', feed['name'])}")
                feed_data = feedparser.parse(feed["url"])
                crypto_only = feed.get("crypto_only", False)
                crypto_keywords = self.config.get("crypto_keywords", [])

                count = 0
                for entry in feed_data.entries[:30]:
                    try:
                        pub_date = datetime.now()
                        if hasattr(entry, "published_parsed") and entry.published_parsed:
                            pub_date = datetime(*entry.published_parsed[:6])
                            if pub_date < cutoff_time:
                                continue

                        title = entry.get("title", "")
                        summary = entry.get("summary", entry.get("description", ""))
                        url = entry.get("link", "")

                        # Check crypto keywords
                        if not crypto_only:
                            text = (title + " " + summary).lower()
                            if not any(kw.lower() in text for kw in crypto_keywords):
                                continue

                        # AI summarize
                        ai_result = summarize_with_deepseek(title, summary, url)

                        articles.append({
                            "title": title,
                            "title_cn": ai_result["title_cn"],
                            "summary": ai_result["summary"],
                            "source": feed["name"],
                            "source_zh": feed.get("zh_name", feed["name"]),
                            "url": url,
                            "published": pub_date
                        })
                        count += 1
                    except Exception as e:
                        continue

                logger.info(f"   âœ“ Found {count} crypto articles")
            except Exception as e:
                logger.error(f"   âœ— Error: {e}")

        articles.sort(key=lambda x: x["published"].timestamp(), reverse=True)
        max_articles = self.config.get("processing", {}).get("max_articles", 10)
        logger.info(f"ğŸ“Š Total: {len(articles)} articles (limited to {max_articles})")
        return articles[:max_articles]


def fetch_btc_price() -> Dict:
    """Fetch BTC price from CoinGecko"""
    try:
        resp = requests.get(
            "https://api.coingecko.com/api/v3/simple/price",
            params={"ids": "bitcoin", "vs_currencies": "usd", "include_24hr_change": "true"},
            timeout=10
        )
        if resp.status_code == 200:
            data = resp.json()
            return {
                "price": data.get("bitcoin", {}).get("usd", 0),
                "change_24h": data.get("bitcoin", {}).get("usd_24h_change", 0)
            }
    except Exception as e:
        logger.debug(f"BTC price fetch failed: {e}")
    return {"price": 0, "change_24h": 0}


def format_briefing(articles: List[Dict], prices: Dict = None) -> str:
    """Format articles into beautiful briefing (å¤åˆ»æœ¬åœ°æ ¼å¼)"""
    if not articles:
        return "ğŸ“° *åŠ å¯†æ–°é—»ç®€æŠ¥*\n\næœ¬å‘¨æœŸæœªæ‰¾åˆ°æ–°æ–‡ç« ã€‚"

    lines = []

    # Header
    lines.append("*åŠ å¯†æ–°é—»ç®€æŠ¥*")
    lines.append(datetime.now().strftime('%Y-%m-%d %H:%M'))
    lines.append("")

    # BTC price
    if prices and prices.get("price"):
        change = prices.get("change_24h", 0)
        change_str = f"{change:+.2f}%" if change else ""
        lines.append(f"*â‚¿ ${prices['price']:,.0f} {change_str}*")
        lines.append("")

    # Articles: æ ‡é¢˜ã€æ‘˜è¦ã€æ¥æºã€æ—¶é—´ã€é“¾æ¥
    for i, article in enumerate(articles, 1):
        title = article.get("title_cn", article.get("title", ""))
        summary = article.get("summary", "")
        source = article.get("source_zh", article.get("source", ""))
        url = article.get("url", "")
        time_str = article["published"].strftime("%H:%M")

        lines.append(f"*{i} {title}*")
        lines.append(f"{summary}")
        if url:
            lines.append(f"[{source}]({url}) | {time_str}")
        else:
            lines.append(f"_{source} | {time_str}_")
        lines.append("")

    return "\n".join(lines)


def send_to_telegram(articles: List[Dict], prices: Dict = None) -> bool:
    """Send formatted briefing to Telegram"""
    TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")
    CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID")

    if not TOKEN or not CHAT_ID:
        logger.error("Telegram credentials not configured!")
        return False

    # Use beautiful format
    message = format_briefing(articles, prices)
    logger.info("ğŸ“¤ Sending to Telegram...")

    # Send with Markdown parse_mode
    if len(message) > 4000:
        chunks = [message[i:i+4000] for i in range(0, len(message), 4000)]
        for i, chunk in enumerate(chunks, 1):
            resp = requests.post(
                f"https://api.telegram.org/bot{TOKEN}/sendMessage",
                json={"chat_id": CHAT_ID, "text": chunk, "parse_mode": "Markdown", "disable_web_page_preview": True},
                timeout=30
            )
            if resp.status_code != 200:
                logger.error(f"Failed to send chunk {i}")
                return False
    else:
        resp = requests.post(
            f"https://api.telegram.org/bot{TOKEN}/sendMessage",
            json={"chat_id": CHAT_ID, "text": message, "parse_mode": "Markdown", "disable_web_page_preview": True},
            timeout=30
        )

    if resp.status_code == 200:
        logger.info(f"âœ“ Successfully sent {len(articles)} articles to Telegram!")
        return True
    else:
        logger.error(f"Failed to send: {resp.status_code}")
        return False


def main():
    print("=" * 60)
    print("ğŸš€ Crypto News Briefing - GitHub Actions")
    print("=" * 60)
    print()

    # Check API key
    if not os.environ.get("DEEPSEEK_API_KEY"):
        logger.warning("âš ï¸ DEEPSEEK_API_KEY not set, using raw titles")

    # Load config
    with open("config.yaml", "r") as f:
        config = yaml.safe_load(f)

    # Step 1: Fetch BTC price
    logger.info("ğŸ“Š Fetching BTC price...")
    prices = fetch_btc_price()
    if prices.get("price"):
        logger.info(f"   BTC: ${prices['price']:,.0f} ({prices['change_24h']:+.2f}%)")

    # Step 2: Fetch RSS
    logger.info("\nğŸ“¥ Fetching RSS feeds...")
    fetcher = RSSFetcher(config)
    articles = fetcher.fetch_all()

    if not articles:
        logger.warning("No articles found!")
        return

    # Step 3: Send to Telegram
    print()
    logger.info("ğŸ“‹ Preview:")
    for i, a in enumerate(articles[:3], 1):
        logger.info(f"   {i}. {a['title_cn'][:40]}...")
    print()

    if send_to_telegram(articles, prices):
        print("=" * 60)
        print("âœ… Done! Check Telegram for the briefing.")
        print("=" * 60)
    else:
        print("âŒ Failed to send to Telegram")


if __name__ == "__main__":
    main()
