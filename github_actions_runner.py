#!/usr/bin/env python3
"""
åŠ å¯†è´§å¸æ–°é—»ç®€æŠ¥ - GitHub Actions ç‰ˆæœ¬
å®Œå…¨å¤åˆ»æœ¬åœ°éƒ¨ç½² (src/main.py) çš„æ‰€æœ‰åŠŸèƒ½ï¼š
- RSS æŠ“å– (SSL å¤„ç†) â†’ å¤„ç†å»é‡ â†’ AI æ‘˜è¦(ç¿»è¯‘+æ‘˜è¦) â†’ ç²¾ç¾æ ¼å¼å‘é€
"""

import os, sys, yaml, logging, ssl, urllib.request, feedparser, requests
from datetime import datetime, timedelta, timezone
from typing import List, Dict, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
from bs4 import BeautifulSoup

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)

# Beijing timezone for display
BJ_TIMEZONE = timezone(timedelta(hours=8))


# ============== SSL å¤„ç† ==============
_orig_urlopen = urllib.request.urlopen

def _patched_urlopen(url, *a, **k):
    """ä¿®å¤ SSL å’Œ URL ç±»å‹é—®é¢˜"""
    try:
        if isinstance(url, urllib.request.Request):
            return _orig_urlopen(url, *a, **k, context=ssl_context)
        return _orig_urlopen(url, *a, **k, context=ssl_context)
    except Exception:
        pass
    
    # Fallback: ç›´æ¥ä½¿ç”¨ requests
    if isinstance(url, urllib.request.Request):
        url = url.full_url
    try:
        resp = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=30)
        return resp.raw
    except:
        return _orig_urlopen(url, *a, **k)

urllib.request.urlopen = _patched_urlopen

ssl_context = ssl.create_default_context()
ssl_context.check_hostname = False
ssl_context.verify_mode = ssl.CERT_NONE


# ============== å·¥å…·å‡½æ•° ==============
def clean_text(text: str) -> str:
    """æ¸…ç† HTML æ ‡ç­¾å’Œå¤šä½™ç©ºæ ¼"""
    if not text:
        return ""
    import re
    text = re.sub(r'<[^>]+>', '', text)
    text = re.sub(r'\s+', ' ', text)
    return text.strip()


def safe_get(data: dict, *keys, default="") -> str:
    """å®‰å…¨è·å–åµŒå¥—å­—å…¸å€¼"""
    for key in keys:
        if isinstance(data, dict):
            data = data.get(key, default)
        else:
            return default
    return data if data else default


# ============== AI æ‘˜è¦æ¨¡å— ==============
def fetch_article_content(url: str) -> str:
    """è·å–æ–‡ç« æ­£æ–‡å†…å®¹"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
            'Accept': 'text/html,application/xhtml+xml'
        }
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()

        soup = BeautifulSoup(response.content, 'html.parser')

        for tag in soup(['script', 'style', 'nav', 'footer', 'header', 'aside', 'nav']):
            tag.decompose()

        content = None
        selectors = [
            'article', '[role="main"]', '.article-content', '.post-content',
            '.entry-content', '.content-body', '.story-body', 'main',
            '.news-content', '.article-body'
        ]

        for selector in selectors:
            elem = soup.select_one(selector)
            if elem and len(elem.get_text(strip=True)) > 200:
                content = elem
                break

        if not content:
            content = soup.find('body')

        if content:
            text = content.get_text(separator=' ', strip=True)
            return clean_text(text)[:3000]

        return ""
    except Exception as e:
        logger.debug(f"Failed to fetch article: {e}")
        return ""


def summarize_with_deepseek(title: str, summary: str, url: str = "") -> Dict[str, str]:
    """ä½¿ç”¨ DeepSeek AI ç¿»è¯‘æ ‡é¢˜å¹¶ç”Ÿæˆæ‘˜è¦"""
    api_key = os.environ.get("DEEPSEEK_API_KEY")
    if not api_key:
        return {"title_cn": clean_text(title), "summary": clean_text(summary)[:150]}

    try:
        content = fetch_article_content(url) if url else ""

        if content:
            prompt = f"""è¯·ç”¨ä¸­æ–‡å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

1. å°†æ ‡é¢˜ç¿»è¯‘æˆç®€æ´çš„ä¸­æ–‡ï¼ˆä¸è¶…è¿‡25å­—ï¼‰
2. é˜…è¯»æ–‡ç« å†…å®¹ï¼Œç”¨ä¸è¶…è¿‡100ä¸ªæ±‰å­—æ€»ç»“æ–‡ç« è¦ç‚¹ï¼ˆåªä¿ç•™ä¸åŠ å¯†è´§å¸ç›´æ¥ç›¸å…³çš„å†…å®¹ï¼‰

æ ‡é¢˜ï¼š{title}
æ¥æºï¼š{summary[:500]}

æ–‡ç« å†…å®¹ï¼š
{content[:2000]}

è¯·ç”¨ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
æ ‡é¢˜ç¿»è¯‘ï¼š[ä¸­æ–‡æ ‡é¢˜]
æ‘˜è¦ï¼š[ä¸è¶…è¿‡100å­—çš„æ‘˜è¦]
"""
        else:
            prompt = f"""è¯·ç”¨ä¸­æ–‡å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

1. å°†æ ‡é¢˜ç¿»è¯‘æˆç®€æ´çš„ä¸­æ–‡ï¼ˆä¸è¶…è¿‡25å­—ï¼‰
2. æ ¹æ®æ ‡é¢˜å’Œæ‘˜è¦ç”Ÿæˆä¸€ä¸ªä¸è¶…è¿‡100å­—çš„æ‘˜è¦

æ ‡é¢˜ï¼š{title}
æ‘˜è¦ï¼š{summary[:500]}

è¯·ç”¨ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
æ ‡é¢˜ç¿»è¯‘ï¼š[ä¸­æ–‡æ ‡é¢˜]
æ‘˜è¦ï¼š[ä¸è¶…è¿‡100å­—çš„æ‘˜è¦]
"""

        response = requests.post(
            "https://api.deepseek.com/chat/completions",
            headers={
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            },
            json={
                "model": "deepseek-chat",
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 300,
                "temperature": 0.3
            },
            timeout=30
        )

        if response.status_code == 200:
            data = response.json()
            if data.get("choices") and len(data["choices"]) > 0:
                result = data["choices"][0]["message"]["content"].strip()

                title_cn = clean_text(title)
                summary_cn = clean_text(summary)[:150]

                for line in result.split('\n'):
                    line = line.strip()
                    if line.startswith('æ ‡é¢˜ç¿»è¯‘ï¼š'):
                        title_cn = line.replace('æ ‡é¢˜ç¿»è¯‘ï¼š', '').strip()
                    elif line.startswith('æ‘˜è¦ï¼š'):
                        summary_cn = line.replace('æ‘˜è¦ï¼š', '').strip()

                return {"title_cn": title_cn, "summary": summary_cn}

    except Exception as e:
        logger.debug(f"DeepSeek API error: {e}")

    return {"title_cn": clean_text(title), "summary": clean_text(summary)[:150]}


# ============== RSS æŠ“å–æ¨¡å— ==============
def fetch_single_feed(feed: dict, cutoff_time, crypto_keywords: List[str]) -> List[Dict]:
    """å•çº¿ç¨‹æŠ“å–å•ä¸ª RSS æº"""
    url = feed.get("url", "")
    name = feed.get("name", "Unknown")
    crypto_only = feed.get("crypto_only", False)
    priority = feed.get("priority", 3)
    articles = []

    try:
        logger.info(f"ğŸ“¡ Fetching: {name}")

        # ä½¿ç”¨ requests è·å–å†…å®¹
        resp = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=15)

        if resp.status_code != 200:
            logger.warning(f"   âœ— HTTP {resp.status_code}")
            return []

        feed_data = feedparser.parse(resp.content)

        if not feed_data.entries:
            logger.warning(f"   âœ— No entries")
            return []

        count = 0
        for entry in feed_data.entries[:30]:
            try:
                pub_date = datetime.now(BJ_TIMEZONE)
                if hasattr(entry, "published_parsed") and entry.published_parsed:
                    try:
                        utc_dt = datetime(*entry.published_parsed[:6], tzinfo=timezone.utc)
                        pub_date = utc_dt.astimezone(BJ_TIMEZONE)
                    except:
                        pass
                    if pub_date < cutoff_time:
                        continue

                title = safe_get(entry, "title", default="")
                if not title:
                    continue

                summary = safe_get(entry, "summary", default="") or safe_get(entry, "description", default="")
                url = safe_get(entry, "link", default="")

                # è¿‡æ»¤åŠ å¯†è´§å¸å…³é”®è¯
                if not crypto_only:
                    text = (title + " " + summary).lower()
                    if not any(kw.lower() in text for kw in crypto_keywords):
                        continue

                # AI æ‘˜è¦
                ai_result = summarize_with_deepseek(title, summary, url)

                articles.append({
                    "title": title,
                    "title_cn": ai_result["title_cn"],
                    "summary": ai_result["summary"],
                    "source": name,
                    "url": url,
                    "published": pub_date,
                    "priority": priority
                })
                count += 1
            except Exception:
                continue

        logger.info(f"   âœ“ Found {count} crypto articles")
        return articles

    except Exception as e:
        logger.error(f"   âœ— Error: {str(e)[:50]}")
        return []


class RSSFetcher:
    """RSS æŠ“å–å™¨ - ä¼˜åŒ–ç‰ˆï¼Œæ”¯æŒå¹¶è¡ŒæŠ“å–"""
    def __init__(self, config: dict):
        self.config = config
        self.feeds = config.get("rss_sources", [])
        self.lookback_hours = config.get("processing", {}).get("hours_lookback", 12)

    def fetch_all(self) -> List[Dict]:
        articles = []
        cutoff_time = datetime.now(BJ_TIMEZONE) - timedelta(hours=self.lookback_hours)
        crypto_keywords = self.config.get("crypto_keywords", [])

        # è¿‡æ»¤å¯ç”¨çš„æº
        enabled_feeds = [f for f in self.feeds if f.get("enabled", True)]

        # å¹¶è¡ŒæŠ“å– (æœ€å¤š 5 ä¸ªå¹¶å‘)
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = {
                executor.submit(fetch_single_feed, feed, cutoff_time, crypto_keywords): feed
                for feed in enabled_feeds
            }

            for future in as_completed(futures):
                feed_articles = future.result()
                articles.extend(feed_articles)

        # æŒ‰æ—¶é—´æ’åº
        articles.sort(key=lambda x: x["published"].timestamp(), reverse=True)

        max_articles = self.config.get("processing", {}).get("max_articles", 10)
        logger.info(f"ğŸ“Š Total: {len(articles)} articles (max {max_articles})")
        return articles[:max_articles]


# ============== ä»·æ ¼è·å–æ¨¡å— ==============
def fetch_btc_price() -> Dict:
    """è·å– BTC ä»·æ ¼"""
    try:
        resp = requests.get(
            "https://api.coingecko.com/api/v3/simple/price",
            params={"ids": "bitcoin", "vs_currencies": "usd", "include_24hr_change": "true"},
            timeout=10
        )
        if resp.status_code == 200:
            data = resp.json()
            btc = data.get("bitcoin", {})
            return {
                "price": btc.get("usd", 0),
                "change_24h": btc.get("usd_24h_change", 0)
            }
    except Exception as e:
        logger.debug(f"BTC price fetch failed: {e}")
    return {"price": 0, "change_24h": 0}


# ============== Telegram æ ¼å¼åŒ–æ¨¡å— ==============
def format_briefing(articles: List[Dict], prices: Dict = None) -> str:
    """æ ¼å¼åŒ–ç®€æŠ¥"""
    if not articles:
        return "ğŸ“° *åŠ å¯†æ–°é—»ç®€æŠ¥*\n\næœ¬å‘¨æœŸæœªæ‰¾åˆ°æ–°æ–‡ç« ã€‚"

    lines = []

    lines.append("*åŠ å¯†æ–°é—»ç®€æŠ¥*")
    lines.append(datetime.now(BJ_TIMEZONE).strftime('%Y-%m-%d %H:%M'))
    lines.append("")

    if prices and prices.get("price"):
        change = prices.get("change_24h", 0)
        change_str = f"{change:+.2f}%" if change else ""
        lines.append(f"*â‚¿ ${prices['price']:,.0f} {change_str}*")
        lines.append("")

    for i, article in enumerate(articles, 1):
        title = article.get("title_cn", article.get("title", ""))
        summary = article.get("summary", "")
        source = article.get("source", "Unknown")
        url = article.get("url", "")
        time_str = article["published"].strftime("%H:%M")

        lines.append(f"*{i} {title}*")
        lines.append(f"{summary}")
        if url:
            lines.append(f"[{source}]({url}) | {time_str}")
        else:
            lines.append(f"_{source} | {time_str}_")
        lines.append("")

    return "\n".join(lines)


def send_to_telegram(articles: List[Dict], prices: Dict = None) -> bool:
    """å‘é€åˆ° Telegram"""
    TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")
    CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID")

    if not TOKEN or not CHAT_ID:
        logger.error("Telegram credentials not configured!")
        return False

    message = format_briefing(articles, prices)
    logger.info("ğŸ“¤ Sending to Telegram...")

    if len(message) > 4000:
        chunks = [message[i:i+4000] for i in range(0, len(message), 4000)]
        for i, chunk in enumerate(chunks, 1):
            resp = requests.post(
                f"https://api.telegram.org/bot{TOKEN}/sendMessage",
                json={
                    "chat_id": CHAT_ID,
                    "text": chunk,
                    "parse_mode": "Markdown",
                    "disable_web_page_preview": True
                },
                timeout=30
            )
            if resp.status_code != 200:
                logger.error(f"Failed chunk {i}: {resp.status_code}")
                return False
    else:
        resp = requests.post(
            f"https://api.telegram.org/bot{TOKEN}/sendMessage",
            json={
                "chat_id": CHAT_ID,
                "text": message,
                "parse_mode": "Markdown",
                "disable_web_page_preview": True
            },
            timeout=30
        )

    if resp.status_code == 200:
        logger.info(f"âœ“ Successfully sent {len(articles)} articles to Telegram!")
        return True
    else:
        logger.error(f"Failed to send: {resp.status_code}")
        return False


# ============== ä¸»å‡½æ•° ==============
def main():
    """ä¸»å…¥å£"""
    print("=" * 60)
    print("ğŸš€ Crypto News Briefing - GitHub Actions")
    print("=" * 60)
    print()

    if not os.environ.get("DEEPSEEK_API_KEY"):
        logger.warning("âš ï¸ DEEPSEEK_API_KEY not set")

    with open("config.yaml", "r") as f:
        config = yaml.safe_load(f)

    logger.info("ğŸ“Š Step 0: Fetching market prices...")
    prices = fetch_btc_price()
    if prices.get("price"):
        change = prices.get("change_24h", 0)
        change_str = f"{change:+.2f}%" if change else ""
        logger.info(f"   BTC: ${prices['price']:,.0f} {change_str}")

    logger.info("\nğŸ“¥ Step 1: Fetching RSS feeds (parallel)...")
    fetcher = RSSFetcher(config)
    articles = fetcher.fetch_all()

    if not articles:
        logger.warning("No articles found!")
        return

    print()
    logger.info("ğŸ“‹ Preview:")
    for i, a in enumerate(articles[:5], 1):
        logger.info(f"   {i}. {a['title_cn'][:40]}... ({a['source']})")
    print()

    logger.info("ğŸ“¤ Step 2: Sending to Telegram...")
    if send_to_telegram(articles, prices):
        print("=" * 60)
        print("âœ… Done! Check Telegram for the briefing.")
        print("=" * 60)
    else:
        print("âŒ Failed to send to Telegram")


if __name__ == "__main__":
    main()
