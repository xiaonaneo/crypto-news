name: Crypto News Briefing

on:
  schedule:
    # æ¯ 2 å°æ—¶è‡ªåŠ¨è¿è¡Œ (UTC æ—¶é—´)
    # UTC 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22
    - cron: '0 */2 * * *'
  
  # æ‰‹åŠ¨è§¦å‘
  workflow_dispatch:
  
  # ä»£ç æŽ¨é€æ—¶è¿è¡Œï¼ˆæµ‹è¯•ç”¨ï¼‰
  push:
    branches: [main]
    paths-ignore:
      - 'README.md'
      - '*.md'

jobs:
  send-crypto-news:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    
    steps:
      # 1. æ£€å‡ºä»£ç 
      - name: Checkout code
        uses: actions/checkout@v4
      
      # 2. è®¾ç½® Python
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      # 3. å®‰è£…ä¾èµ–
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyyaml requests feedparser python-telegram-bot apscheduler beautifulsoup4 lxml python-dotenv
      
      # 4. åˆ›å»ºçŽ¯å¢ƒå˜é‡æ–‡ä»¶
      - name: Create .env file
        run: |
          echo "TELEGRAM_BOT_TOKEN=${{ secrets.TELEGRAM_BOT_TOKEN }}" > .env
          echo "TELEGRAM_CHAT_ID=${{ secrets.TELEGRAM_CHAT_ID }}" >> .env
          echo "CRYPTO_KEYWORDS=bitcoin,ethereum,crypto,cryptocurrency,blockchain,btc,eth,solana" >> .env
          echo "RSS_HOURS_LOOKBACK=24" >> .env
          echo "MAX_ARTICLES=15" >> .env
          echo "SUMMARY_LENGTH=100" >> .env
        shell: bash
      
      # 5. ä¿®å¤ SSL é—®é¢˜
      - name: Fix SSL for RSS feeds
        run: |
          cat > modules/rss_fetcher_ssl.py << 'PYEOF'
import feedparser
import ssl
import urllib.request
from datetime import datetime, timedelta
from typing import List, Dict
import hashlib
import re
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def create_unverified_ssl_context():
    context = ssl.create_default_context()
    context.check_hostname = False
    context.verify_mode = ssl.CERT_NONE
    return context

_original_urlopen = urllib.request.urlopen

def _patched_urlopen(url, *args, **kwargs):
    try:
        return _original_urlopen(url, *args, **kwargs, context=create_unverified_ssl_context())
    except Exception as e:
        import urllib.request
        req = urllib.request.Request(url)
        with urllib.request.urlopen(req, timeout=30) as response:
            return response

urllib.request.urlopen = _patched_urlopen

class RSSFetcher:
    def __init__(self, config: dict):
        self.config = config
        self.feeds = config.get('rss_sources', [])
        self.crypto_keywords = config.get('crypto_keywords', [])
        processing_config = config.get('processing', {})
        self.lookback_hours = processing_config.get('hours_lookback', 24)
    
    def is_crypto_related(self, title: str = "", summary: str = "", source_name: str = "", crypto_only: bool = False) -> bool:
        if crypto_only:
            return True
        if not title and not summary:
            return True
        text = f"{title} {summary}".lower()
        return any(kw.lower() in text for kw in self.crypto_keywords)
    
    def get_article_hash(self, url: str) -> str:
        return hashlib.md5(url.encode()).hexdigest()
    
    def parse_date(self, entry) -> datetime:
        try:
            if hasattr(entry, 'published_parsed') and entry.published_parsed:
                return datetime(*entry.published_parsed[:6])
            elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:
                return datetime(*entry.updated_parsed[:6])
        except:
            pass
        return datetime.now()
    
    def clean_text(self, text: str, max_length: int = 200) -> str:
        if not text:
            return ""
        text = re.sub(r'<[^>]+>', '', text)
        text = ' '.join(text.split())
        if len(text) > max_length:
            text = text[:max_length] + "..."
        return text.strip()
    
    def fetch_feed(self, feed_info: dict) -> List[Dict]:
        articles = []
        if not feed_info.get('enabled', True):
            return articles
        
        try:
            logger.info(f"Fetching: {feed_info['name']}")
            feed = feedparser.parse(feed_info['url'])
            
            cutoff_time = datetime.now() - timedelta(hours=self.lookback_hours)
            crypto_only = feed_info.get('crypto_only', False)
            
            for entry in feed.entries[:50]:
                pub_date = self.parse_date(entry)
                if pub_date < cutoff_time:
                    continue
                
                title = entry.get('title', '')
                summary = entry.get('summary', entry.get('description', ''))
                
                if not self.is_crypto_related(title, summary, feed_info['name'], crypto_only):
                    continue
                
                article = {
                    'hash': self.get_article_hash(entry.link),
                    'source': feed_info['name'],
                    'source_priority': feed_info.get('priority', 1),
                    'title': self.clean_text(title),
                    'url': entry.link,
                    'summary': self.clean_text(summary, 300),
                    'published': pub_date,
                    'engagement': 0
                }
                articles.append(article)
            
            logger.info(f"âœ“ {feed_info['name']}: {len(articles)} articles")
            
        except Exception as e:
            logger.error(f"âœ— Error {feed_info['name']}: {e}")
        
        return articles
    
    def fetch_all(self) -> List[Dict]:
        all_articles = []
        for feed in self.feeds:
            articles = self.fetch_feed(feed)
            all_articles.extend(articles)
        
        all_articles.sort(key=lambda x: (-x['source_priority'], x['published']), reverse=True)
        logger.info(f"Total: {len(all_articles)} articles from {len(self.feeds)} feeds")
        return all_articles
PYEOF
          echo "âœ… Created SSL-patched RSS fetcher"
      
      # 6. åˆ›å»ºä¸»ç¨‹åº
      - name: Create main program
        run: |
          cat > send_news.py << 'PYEOF'
import sys
import os
import yaml
import logging
from datetime import datetime
from modules.rss_fetcher_ssl import RSSFetcher
import requests

# Load config
with open('config.yaml', 'r') as f:
    config = yaml.safe_load(f)

# Load env vars
TOKEN = os.environ.get('TELEGRAM_BOT_TOKEN')
CHAT_ID = os.environ.get('TELEGRAM_CHAT_ID')

print("=" * 70)
print("ðŸš€ Crypto News Briefing - GitHub Actions")
print("=" * 70)
print()

# Fetch news
print("ðŸ“¥ Fetching crypto news...")
fetcher = RSSFetcher(config)
articles = fetcher.fetch_all()
print(f"   Found {len(articles)} articles")
print()

# Process - take top 10
articles = articles[:10]

# Build message
message_lines = [
    "ðŸ“° *Crypto News Briefing*",
    f"_{datetime.now().strftime('%Y-%m-%d %H:%M UTC')}_",
    "",
    f"ðŸ“Š Found {len(articles)} crypto articles",
    "",
    "â”€" * 30,
    ""
]

for i, article in enumerate(articles, 1):
    emoji = "ðŸ“°" if article['source'] == 'CoinTelegraph' else "ðŸ“Š"
    message_lines.append(f"{emoji} *{i}. {article['title']}*")
    message_lines.append("")
    message_lines.append(f"   ðŸ“ {article['source']} â€¢ ðŸ• {article['published'].strftime('%H:%M')}")
    message_lines.append("")

message_lines.extend([
    "â”€" * 30,
    "",
    "ðŸ¤– *Automated Crypto News Briefing*",
    "ðŸ“¡ Sources: CoinTelegraph, CoinDesk"
])

message = "\n".join(message_lines)

# Send to Telegram
print("ðŸ“¤ Sending to Telegram...")
resp = requests.post(
    f"https://api.telegram.org/bot{TOKEN}/sendMessage",
    json={
        "chat_id": CHAT_ID,
        "text": message,
        "parse_mode": "Markdown",
        "disable_web_page_preview": True
    },
    timeout=30
)

if resp.status_code == 200:
    print()
    print("=" * 70)
    print("âœ… SUCCESS! News sent to Telegram!")
    print("=" * 70)
else:
    print(f"âŒ FAILED: {resp.status_code}")
    print(resp.text)
    sys.exit(1)
PYEOF
          echo "âœ… Created send_news.py"
      
      # 7. è¿è¡Œå‘é€ç¨‹åº
      - name: Send crypto news
        run: python send_news.py

